{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# binary concrete spike and slab group-wise  poisson regression\n",
    "In Binary Concrete, you relax the hard binary variable $\\gamma$ element in {0,1} to a continuous approximation using the gumbel-softmax trick:\n",
    "\n",
    "$$\n",
    "\\gamma_i = \\mathrm{sigmoid}\\left(\\frac{\\log \\alpha + \\text{Gumbel noise}}{\\tau}\\right)\n",
    "$$\n",
    "\n",
    "- you sample $\\gamma_i$ during inference\n",
    "- Those samples represent how \"on\" or \"off\" the gate is for each group\n",
    "- over many posterior samples,  ($\\gamma_i$), but tends to 0 or 1 (with annealing of  $\\tau$ )\n",
    "\n",
    "## use this if: \n",
    "- You want principled model selection\n",
    "- You're comparing sparsity structures\n",
    "- You want to report posterior inclusion probabilities (which only stochastic gates give you)\n",
    "\n",
    "## deets\n",
    "\n",
    " - Works in SVI\t\n",
    "-  Matches prior stochasticity\t\n",
    "-  Encourages sparsity\t\t\n",
    "- Supports uncertainty quantification by capturing gate uncertainty\n",
    "- Convergence stabilityL:Ô∏è Slightly noisier early on\n",
    "üîÆ Predictive calibration\t\t‚úÖ Better calibrated posterior\n",
    "üßä Temperature Annealing\t\t‚úÖ Crucial for gating effect\n",
    "\n",
    "\n",
    "## posterior inclusion computation\n",
    "So how do you get the posterior inclusion probability?\n",
    "After inference (SVI), collect all the samples of gamma_i:\n",
    "\n",
    "gamma_samples = posterior_samples[\"gamma_3\"]  # shape: (n_samples,)\n",
    "Then simply compute the mean:\n",
    "\n",
    "inclusion_prob = jnp.mean(gamma_samples) <br>\n",
    "- If inclusion_prob ‚âà 1.0: very strong evidence this group matters\n",
    "- If ‚âà 0.0: the group is off\n",
    "- If ‚âà 0.5: uncertain, possibly borderline <br>\n",
    "\n",
    "This is a posterior estimate of our posterior belief of group inclusion: <br>\n",
    "$$\n",
    "p(\\gamma_i=1|data) ~= Expectation[$\\gamma_i$|data]\n",
    "$$\n",
    "\n"
   ],
   "id": "8966bea62f669d8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:12:29.561205Z",
     "start_time": "2025-03-31T19:12:28.214213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#imports\n",
    "from BayesBrain import models,datasim,glm,utils\n",
    "import jax.numpy as jnp\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/anaconda3/envs/main/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Simulate poisson data with 2 groups, 1 is very relevant, the other not really",
   "id": "554c85df385adaca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:12:30.004084Z",
     "start_time": "2025-03-31T19:12:30.001763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sims=datasim.simulate_poisson_grouped()\n",
    "X_dsgn=sims[0]\n",
    "Y=sims[1]"
   ],
   "id": "4e6a0ccf3db50000",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### obtain default params for model",
   "id": "e7d9361a64612db8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T19:12:36.595088Z",
     "start_time": "2025-03-31T19:12:32.813855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paramglm=utils.param_defaults_bayes(modname='grouped_ss_concrete')\n",
    "paramglm.update({'probs':0.1})\n",
    "paramglm['visteps']=50000\n",
    "paramglm['prior_alpha']=0.01\n",
    "paramglm['type']='zip'\n",
    "mod2fitall = glm.PoissonGLMbayes()\n",
    "\n",
    "mod2fitall.add_data(y=jnp.array(Y))\n",
    "\n",
    "# Learn smoothness from data\n",
    "mod2fitall.define_model(model='grouped_ss_concrete', basis_x_list=X_dsgn, S_list=None,\n",
    "                          tensor_basis_list=None, S_tensor_list=None)\n",
    "\n",
    "mod2fitall.fit(params=paramglm,  fit_intercept=True)\n",
    "\n",
    "#Got to fix post sampling checking to beta_i * lambda_ard[i]\n",
    "# mod2fitall.sample_posterior(5000).summarize_posterior(90).coeff_relevance()\n"
   ],
   "id": "ea7db9c771f6aa65",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:02<00:00, 4896.99it/s, init loss: 1032116.3125, avg. loss [9501-10000]: 1934.1447]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<GLM.glm.PoissonGLMbayes at 0x2aed58ca0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import jax\n",
    "nsamples=5000\n",
    "poster = mod2fitall.guide.sample_posterior(jax.random.PRNGKey(1), mod2fitall.svi_result.params,\n",
    "                                                                 sample_shape=(nsamples,))"
   ],
   "id": "245635a25f2b50d8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
